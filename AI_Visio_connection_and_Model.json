{
  "name": "AI_Visio_connection_and_Model",
  "nodes": [
    {
      "parameters": {
        "url": "http://127.0.0.1:11434/v1/models",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {}
          ]
        },
        "options": {}
      },
      "id": "d8f03d4d-613c-4bc7-8b78-3f434a05f8e1",
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        320,
        380
      ]
    },
    {
      "parameters": {
        "jsCode": "// Extract the models from the HTTP request response (assuming they are inside \"data\")\nconst models = $input.first().json.data.map(model => model.id);\n\n// Return the models in a structured response\nreturn [\n  {\n    json: {\n      status: 'Success',\n      availableModels: models\n    }\n  }\n];\n"
      },
      "id": "50f8ed10-881e-4ae7-bbb4-778a22d33301",
      "name": "Code",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        500,
        380
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json.availableModels }}",
        "options": {}
      },
      "id": "d10767a1-d4ac-4cc2-8691-0a546957e810",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        720,
        380
      ]
    },
    {
      "parameters": {
        "content": "## Connection and Ollama\n** Connects via Webhook, and connects to API\n** List models back to AIChatPane",
        "height": 300,
        "width": 956
      },
      "id": "073c6bc2-14b9-43e6-8f21-7f9e5f13f389",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        60,
        260
      ]
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "/connection_model_list",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "83bf1ad8-796b-4822-9c21-dda85301098a",
      "name": "API_Connection_model_visio",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        140,
        380
      ],
      "webhookId": "52989a61-80e0-4499-bc5d-b1e822792bad"
    },
    {
      "parameters": {
        "model": "llama3.2:latest",
        "options": {}
      },
      "id": "1933afb7-4ab6-4f6a-8155-8c13802118bb",
      "name": "Ollama Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        120,
        680
      ],
      "credentials": {
        "ollamaApi": {
          "id": "OuW1SzikhVbQMEOL",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "text",
        "options": {}
      },
      "id": "7ac248ef-b6ea-4a49-8c94-ef79280093f8",
      "name": "Action_response1",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        920,
        500
      ],
      "alwaysOutputData": false
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "={{ $json.text }}",
        "options": {}
      },
      "id": "a9cf3ee6-4d39-4b3a-89aa-592074509690",
      "name": "Respond chat_from_manager",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        740,
        220
      ],
      "alwaysOutputData": false
    },
    {
      "parameters": {
        "jsCode": "// Extract the 'reply' field from the input JSON\nlet replyText = $json.reply;\n\n// Ensure that we only return the reply text\nreturn [\n  {\n    \"text\": replyText\n  }\n];\n"
      },
      "id": "a7f7c323-70eb-4149-935b-f1326aacdb49",
      "name": "Code",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        500,
        220
      ]
    },
    {
      "parameters": {
        "mode": "passThrough"
      },
      "id": "942a452d-1208-43cc-ad1c-8eb050cb5fe5",
      "name": "Merge Chat_Visio and Chat",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 1,
      "position": [
        -680,
        240
      ]
    },
    {
      "parameters": {
        "model": "llama3.2:latest",
        "options": {}
      },
      "id": "9c8fd97d-5efa-4ec9-9603-7812687d9231",
      "name": "Ollama Model",
      "type": "@n8n/n8n-nodes-langchain.lmOllama",
      "typeVersion": 1,
      "position": [
        -460,
        480
      ],
      "credentials": {
        "ollamaApi": {
          "id": "OuW1SzikhVbQMEOL",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "let output;\n\ntry {\n    // Try to parse the JSON from the Manager response\n    output = JSON.parse($json.text);\n} catch (error) {\n    // If parsing fails, handle it as a regular text message\n    return {\n        route: \"manager\",  // Default route for handling non-JSON inputs\n        reply: $json.text  // Send the raw text as the reply\n    };\n}\n\n// Return both the route and the reply for further processing if JSON parsing succeeds\nreturn {\n    route: output.route,   // Keep route for the Switch node\n    reply: output.reply    // Send reply to the Respond webhook\n};\n"
      },
      "id": "63805d69-9240-4ff4-a5c3-0c9cd27a249e",
      "name": "Code1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -120,
        240
      ]
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.route }}",
                    "rightValue": "=manager",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": "={{ $('Merge Chat_Visio and Chat').item.json.chatInput }}"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "8d8a0903-2a4c-4bf9-9385-b25e8d4c9840",
                    "leftValue": "={{ $json.route }}",
                    "rightValue": "action_agent",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": "={{ $('Merge Chat_Visio and Chat').item.json.chatInput }}"
            }
          ]
        },
        "options": {}
      },
      "id": "31d3ffd0-0840-4278-9049-87dfca3d4989",
      "name": "Switch",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        100,
        240
      ]
    },
    {
      "parameters": {
        "jsCode": "let output;\n\n// Extract the message from the Chat_Visio input and rename it as chatInput\nif ($json.body && $json.body.message) {\n  output = {\n    chatInput: $json.body.message,  // Rename message to chatInput\n  };\n} else {\n  output = {\n    chatInput: \"No chatInput found\",  // Handle case where message is missing\n  };\n}\n\nreturn output;\n"
      },
      "id": "6b128033-b0a9-43dc-97ee-6851c85651eb",
      "name": "Code2",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -960,
        120
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "d826d6f5-694f-402f-9f2f-f4c29ce6f1d5",
      "name": "Chat",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        -1260,
        340
      ],
      "webhookId": "91938835-5f26-42bf-8482-2555230784e7"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=### System:\nYou are the Manager Agent responsible for understanding user input and deciding how to respond.\n\n1. If the user's message is a general chat or question, respond directly with a conversation reply and set the route as `\"manager\"`. \n   Example: \n   - User: \"Hello!\"\n   - Response: { \"route\": \"manager\", \"reply\": \"Hi there! How can I assist you today?\" }\n\n2. If the user's message involves actions like creating, modifying, or deleting, respond with a message indicating that their request has been forwarded and set the route as `\"action_agent\"`.\n   Example: \n   - User: \"Create a red circle.\"\n   - Response: { \"route\": \"action_agent\", \"reply\": \"Your request has been forwarded to the Action Agent.\" }\n\nRespond only with a valid JSON response based on the user's input. \n\n### User:\n{{ $json.chatInput }}\n\n### Assistant:",
        "messages": {
          "messageValues": [
            {
              "message": "={{ $json.chatInput }}"
            }
          ]
        }
      },
      "id": "29575a60-f06b-4d1f-ad5c-f9e3c217f62c",
      "name": "Chat LLM Chain",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        -480,
        240
      ],
      "typeVersion": 1.4,
      "alwaysOutputData": true,
      "notesInFlow": true
    },
    {
      "parameters": {
        "name": "Color_Tool",
        "description": "This tool processes the userâ€™s input and extracts the requested color for a shape. If the user specifies a color such as \"blue\", \"red\", or \"green\", the tool will return the color name as a simple string. If no color is provided, the tool will return \"black\" by default.",
        "language": "python",
        "pythonCode": "def extract_color(input_text):\n    # List of possible colors to detect\n    colors = ['red', 'green', 'blue', 'yellow', 'pink', 'white', 'black', 'orange', 'brown']\n    \n    # Check if any of the colors are in the input text\n    for color in colors:\n        if color in input_text.lower():  # Case-insensitive check for the color\n            return color  # Return the matched color as a simple string\n    \n    # Default color if no match is found\n    return \"black\"\n\n# Retrieve the input from n8n's input object (for example, \"blue\", \"red\", etc.)\ninput_text = globals().get(\"query\", \"default input\")\n\n# Return the extracted color as a plain string\nreturn extract_color(input_text)\n"
      },
      "id": "ddf09589-fba3-4d8e-98ec-7d808cccbc22",
      "name": "Color Tool",
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.1,
      "position": [
        440,
        1060
      ]
    },
    {
      "parameters": {
        "name": "Shape_Tool",
        "description": "This tool extracts the requested shape from the userâ€™s input. The supported shapes are \"circle\", \"rectangle\", \"square\", \"triangle\", and \"ellipse\". It returns the shape as part of a JSON string: {\"shapeType\": \"shape_name\"}.",
        "language": "python",
        "pythonCode": "def extract_shape(input_text):\n    # List of possible shapes to detect\n    shapes = ['Circle', 'Rectangle', 'Square', 'Triangle', 'Ellipse', 'Polygon', 'Hexagon']\n    \n    # Check if any of the shapes are in the input text\n    for shape in shapes:\n        if shape in input_text.lower():  # Case-insensitive check for the shape\n            return f'{{\"ShapeType\": \"{shape}\"}}'  # Return the matched shape as a JSON string\n    \n    # Default shape if no match is found\n    return '{\"ShapeType\": \"{shape}\"}'\n\n# Retrieve the input from n8n's input object (for example, \"circle\", \"square\", etc.)\ninput_text = globals().get(\"query\", \"default input\")\n\n# Return the extracted shape as a plain string\nreturn extract_shape(input_text)"
      },
      "id": "2fa4a017-f3a2-407b-ba59-e082d9872e0d",
      "name": "Shape Tool",
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.1,
      "position": [
        520,
        1060
      ]
    },
    {
      "parameters": {
        "name": "Size_Tool",
        "description": "This tool extracts the size dimensions (width and height) from the userâ€™s input. It expects size inputs in formats like 15x15 or 15 by 15. The tool returns the size in a JSON string: {\"size\": {\"width\": width_value, \"height\": height_value}}. If no size is specified, a default size of {\"width\": 15, \"height\": 15} will be used.",
        "language": "python",
        "pythonCode": "def extract_shape_and_size(input_text):\n    # List of possible shapes to detect\n    shapes = ['Circle', 'Rectangle', 'Square', 'Triangle', 'Ellipse', 'Hexagon']\n    size_keywords = {\n        'small': '{\"width\": 10, \"height\": 10}',\n        'large': '{\"width\": 20, \"height\": 20}',\n        'medium': '{\"width\": 15, \"height\": 15}'\n    }\n    \n    # Default responses\n    extracted_shape = \"rectangle\"\n    extracted_size = None  # No size unless mentioned\n\n    # Check for shape in the input\n    for shape in shapes:\n        if shape in input_text.lower():  # Case-insensitive check for the shape\n            extracted_shape = shape\n            break\n    \n    # Check for qualitative size descriptors in the input\n    for size_keyword, size_value in size_keywords.items():\n        if size_keyword in input_text.lower():\n            extracted_size = size_value  # Match size based on descriptor\n\n    # Build the response\n    shape_json = f'{{\"ShapeType\": \"{extracted_shape}\"}}'\n\n    # If size was found, add it to the response\n    if extracted_size:\n        size_json = f', \"size\": {extracted_size}'\n    else:\n        size_json = ''\n\n    # Return combined JSON string for shape and size\n    return f'{{{shape_json}{size_json}}}'\n\n# Retrieve the input from n8n's input object\ninput_text = globals().get(\"query\", \"default input\")\n\n# Return the extracted shape and size\nreturn extract_shape_and_size(input_text)\n"
      },
      "id": "c9a39b8e-aa82-4d71-9edf-a4c25f5eb968",
      "name": "Size Tool",
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.1,
      "position": [
        600,
        1060
      ]
    },
    {
      "parameters": {
        "name": "Position_Tool",
        "description": "This tool extracts the position from the userâ€™s input, translating positional words like \"center\", \"top left\", \"button corner\" and \"bottom-right\" into coordinates on 0-100 scale button is y=0 and top is y 100. The result is returned as a JSON string: {\"position\": {\"x\": x_value, \"y\": y_value}}\n\nCanvas information:\n- Size: 100x100 units\n- Coordinate system: (0,0) is button left, (100,0) is bottom-right, (0,100) is button left, (100,100) is bottom-right",
        "jsCode": "// Map common positional words to coordinates based on Visio's coordinate system (0, 0) bottom-left\nconst positionMap = {\n    'center': { x: 50, y: 50 },\n    'top left': { x: 0, y: 100 },      // Top-left is (0, 100) in Visio\n    'top right': { x: 100, y: 100 },   // Top-right is (100, 100)\n    'bottom left': { x: 0, y: 0 },     // Bottom-left is (0, 0)\n    'bottom right': { x: 100, y: 0 },  // Bottom-right is (100, 0)\n};\n\n// Convert the input query into lowercase for case-insensitive matching\nconst queryLower = query.toLowerCase();\n\n// Search for keywords in the input query and return the matching position\nfor (const [key, value] of Object.entries(positionMap)) {\n    if (queryLower.includes(key)) {\n        // Return the matched position as a JSON string\n        return JSON.stringify({ position: value });\n    }\n}\n\n// Default to center if no match is found\n//return JSON.stringify({ position: { x: 50, y: 50 } });"
      },
      "id": "cb8505db-ee07-41b8-a229-49625a7fde8a",
      "name": "Position Tool",
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.1,
      "position": [
        680,
        1060
      ]
    },
    {
      "parameters": {
        "method": "=POST",
        "url": "http://localhost:5680/visio-command/",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.output }}",
        "options": {}
      },
      "id": "cd755a3c-b725-4f54-8a10-6d2600510300",
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1140,
        700
      ]
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "{{ $('Merge Chat_Visio and Chat').item.json.chatInput }}",
        "contextWindowLength": 5000
      },
      "id": "d00bdf0d-7627-40bc-8b39-23ecc1979804",
      "name": "Window Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.2,
      "position": [
        320,
        700
      ]
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "/chat-agent",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "86ce539c-c168-490d-9400-8d9001b19e11",
      "name": "Chat_Visio",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -1260,
        120
      ],
      "webhookId": "c09d74e4-06bf-4fde-9c61-879630c13271"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=System:\nYou are an Action Agent responsible for interpreting user requests and generating commands for shapes in a Visio-like system. You have access to a series of tools that extract different parameters needed for creating shapes.\n\nInstructions:\nCanvas information:\n- Size: 100x100 units\n- Coordinate system: (0,0) is top-left, (100,100) is bottom-right\n\n* Your only task is to strictly translate {{ $('Merge Chat_Visio and Chat').item.json.chatInput }} into action and do what the user wants.\nreturn the clean, valid JSON response from the tools, without any tags, explanations, or additional formatting.\n\n* Do not include any language tags (such as <|python_tag|>) or commentary of any kind.\n\n* ALWAYS use the specialized tools to process the userâ€™s request, gather all necessary information (color, shape, size, position) if given, and return the correct JSON response.\n*The JSON response must contain only the data requested by the user.\n\nTool Interaction:\n- Color Tool: Extracts the color for the shape from the user input.\n- Shape Tool: Extracts the shape type from the input.\n- Size Tool: Extracts the dimensions (width and height) from the input.\n- Position Tool: Extracts the position from the input, translating positional words like \"center,\" \"top left\", \"Center\", \"upper right corner\" into numeric coordinates on a x,y scale (min 0, 0 max 100, 100)\n\nCall the Tools:\n- Call the Color Extraction Tool to extract the requested color.\n- Call the Shape Extraction Tool to extract the shape type.\n- Call the Size Extraction Tool to extract the size.\n- Call the Position Extraction Tool to extract the position.\nBuild the Final JSON by adding what is returned from tool:\n{\n   \"command\": \"CreateShape\",\n   \"parameters\": {\n     \"shapeType\": \"{{ shapeType }}\",\n     \"position\": { \"x\": {{ x }}, \"y\": {{ y }} },\n     \"size\": { \"width\": {{ width }}, \"height\": {{ height }} },\n     \"color\": \"{{ color }}\"\n   }\n}\n\nUser message: {{ $('Merge Chat_Visio and Chat').item.json.chatInput }}",
        "options": {}
      },
      "id": "9d8e8f63-06e1-4b36-913d-45f67462ff2b",
      "name": "action_agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        340,
        480
      ]
    }
  ],
  "pinData": {},
  "connections": {
    "HTTP Request": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "API_Connection_model_visio": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat": {
      "main": [
        [
          {
            "node": "Merge Chat_Visio and Chat",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Code2": {
      "main": [
        [
          {
            "node": "Merge Chat_Visio and Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Chat_Visio and Chat": {
      "main": [
        [
          {
            "node": "Chat LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat LLM Chain": {
      "main": [
        [
          {
            "node": "Code1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code1": {
      "main": [
        [
          {
            "node": "Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "action_agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Respond chat_from_manager",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Model": {
      "ai_languageModel": [
        [
          {
            "node": "Chat LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "action_agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Color Tool": {
      "ai_tool": [
        [
          {
            "node": "action_agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Shape Tool": {
      "ai_tool": [
        [
          {
            "node": "action_agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Size Tool": {
      "ai_tool": [
        [
          {
            "node": "action_agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Position Tool": {
      "ai_tool": [
        [
          {
            "node": "action_agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Window Buffer Memory": {
      "ai_memory": [
        [
          {
            "node": "action_agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Chat_Visio": {
      "main": [
        [
          {
            "node": "Code2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "action_agent": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "775f9adc-7afe-410b-a8b6-f112e1f9d351",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "8617a31e3f06210fe687111ab485791c35eb905eedc1db78b92cdc917ac4621b"
  },
  "id": "A0DATPdm2Y4WrcPJ",
  "tags": []
}
